{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# K Nearest Neighbours"
=======
    "# k - Nearest Neighbours"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "KNN is a lazy learner classifier which classifies data based on the 'closeness' factor. It is of two types -\n",
    "    - 1. KNN Classification\n",
    "    - 2. KNN Regression\n",
    "    \n",
    "KNN Algorithm classifies data based on the calculation of Euclidean Distance between the data points and the test instance. A value of 'k' is selected and then the 'k' nearest or closest neighbours are found depending upon the 'k' number of least euclidean distances from the test example. After that the most frequent occuring or 'majority' class is chosen as the classified class for the test instance.\n",
    "\n",
    "-----\n",
    "Training phase and prediction phase. \n",
    "- Training Phase: No training, only store all training instances.\n",
    "- Prediction Phase: When testing instances appear, only then Euclidean distances are calculated and model is learned.\n",
    "\n",
    "-> “Lazy learning”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing right value of 'k'\n",
    "\n",
    "Small k - Captures the fine structure of problem statement, used for smaller data sets, reduced noise between classes\n",
    "\n",
    "Large k - Ignores(less sesnsitive) the fine structure or noise present in the problem space. Used for larger data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If some of the features are more importnant than the others or contains more noise, in that case, we use the Weighted Euclidean Distance approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psuedo Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   1•  Determine parameter K. Generally, K = 1 +- sqrt(n); n = total data points. But, you can also perform KNN on smaller data set (validation set) and determine a good value of 'k'\n",
    "\n",
    "   2• Calculate the distance between the test instance and all the training instances, using one of the Distance methods:\n",
    "              \n",
    "              (i).  'Simple Euclidean Distance     on standardized data'\n",
    "              (ii). 'Weighted Euclidean Distance   on raw data, where weights are based on range of features to bring every \n",
    "                                                                feature on same scale, higher range features (10K, 5K) \n",
    "                                                                will have smaller weights and lower range \n",
    "                                                                ones (1,10) will have higher weights (Mahalanobis distance) \n",
    "                                                                called \"weights for standaridzation\"   \n",
    "             \n",
    "             (iii). 'Weighted Euclidean Distance   on standardized data, where weights are based on importance of features\n",
    "                                                                         more important features will have bigger weight \n",
    "                                                                         values while less important features will have\n",
    "                                                                         smaller weight values, and insignificant features \n",
    "                                                                         will have zero weights,\n",
    "                                                                         called \"weights for importance\"\n",
    "\n",
    "   3• Sort the distances and determine K nearest neighbors and gather the labels\n",
    "\n",
    "   4• Use one of the methods to determine the predicted class/value:\n",
    "       - 'Simple Majority Voting (KNN)'\n",
    "       - 'Distance Weighted Voting (WKNN)' "
=======
    "- Based on the similarity of nearest data points.\n",
    "\n",
    "- Predicts the class which is most occuring or frequent in the nearest neighbours predicted classes\n",
    "\n",
    "- K is chosen, with different iterations. Generally, K = 1 +- sqrt(n); n = total data points"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# KNN Classifier  \n"
=======
    "`KNN is based on the calculation of Euclidean Distance between all data points with the test data point, and choosing 'k' the nearest ones.`"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "raw",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "source": [
    "Predict the Onset of Diabetes (1) or not (0) for a new set of feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This problem is comprised of 768 observations of medical details for Pima indians patents. \n",
    "\n",
    "- All patients are women aged 21 or older. All attributes are numeric, and their units vary from attribute to attribute.\n",
    "\n",
    "- Each record has a class value that indicates whether the patient suffered an onset of diabetes within 5 years of when the measurements were taken Yes(1) or not(0).\n",
    "\n",
    "- A good prediction accuracy is 70%-76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 250,
=======
   "execution_count": 349,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 251,
=======
   "execution_count": 396,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  Iron_content  Calcium_content  Vitamins_deficiency  Beta_nagative  \\\n",
       "0      6           148               72                   35              0   \n",
       "1      1            85               66                   29              0   \n",
       "2      8           183               64                    0              0   \n",
       "3      1            89               66                   23             94   \n",
       "4      0           137               40                   35            168   \n",
       "\n",
       "   Beta_postive  Blood_workout  Age  Class  \n",
       "0          33.6          0.627   50      1  \n",
       "1          26.6          0.351   31      0  \n",
       "2          23.3          0.672   32      1  \n",
       "3          28.1          0.167   21      0  \n",
       "4          43.1          2.288   33      1  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 251,
=======
     "execution_count": 396,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/data_5_2_pima-indians-diabetes.data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 252,
=======
   "execution_count": 386,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 252,
=======
     "execution_count": 386,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 253,
=======
   "execution_count": 387,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Features = list(data.columns)\n",
    "Features.remove(\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization (Feature Scaling)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 254,
=======
   "execution_count": 393,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standarized_data(df):\n",
    "    \n",
    "    for f in Features:\n",
    "        df[f] = (df[f] - df[f].mean())/df[f].std()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 255,
=======
   "execution_count": 394,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639530</td>\n",
       "      <td>0.847771</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>0.203880</td>\n",
       "      <td>0.468187</td>\n",
       "      <td>1.425067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-1.122665</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.683976</td>\n",
       "      <td>-0.364823</td>\n",
       "      <td>-0.190548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>1.942458</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-1.102537</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>-0.105515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-0.997558</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.154433</td>\n",
       "      <td>0.123221</td>\n",
       "      <td>-0.493721</td>\n",
       "      <td>-0.920163</td>\n",
       "      <td>-1.040871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141108</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>-1.503707</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>0.765337</td>\n",
       "      <td>1.408828</td>\n",
       "      <td>5.481337</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0  0.639530      0.847771         0.149543             0.906679   \n",
       "1 -0.844335     -1.122665        -0.160441             0.530556   \n",
       "2  1.233077      1.942458        -0.263769            -1.287373   \n",
       "3 -0.844335     -0.997558        -0.160441             0.154433   \n",
       "4 -1.141108      0.503727        -1.503707             0.906679   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  Class  \n",
       "0      -0.692439      0.203880       0.468187  1.425067      1  \n",
       "1      -0.692439     -0.683976      -0.364823 -0.190548      0  \n",
       "2      -0.692439     -1.102537       0.604004 -0.105515      1  \n",
       "3       0.123221     -0.493721      -0.920163 -1.040871      0  \n",
       "4       0.765337      1.408828       5.481337 -0.020483      1  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 255,
=======
     "execution_count": 394,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = standarized_data(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Steps...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:- Selected a value of 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected value of 'k' is 27\n"
     ]
    }
   ],
   "source": [
    "# Selecting for 3 nearest neighbours\n",
    "k = int(np.sqrt(df.shape[0]))\n",
    "print \"Selected value of 'k' is\", k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:- Prepare the distance functions \n",
    "\n",
    "So as to calulate distance between training and testing data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
=======
    "## Train Test Split"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 257,
=======
   "execution_count": 355,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size):\n",
    "    \n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    \n",
    "    train_index = int(train_size*len(df)) + 1\n",
    "    test_index = train_index + 1\n",
    "    \n",
    "    train_data = df[0:train_index]\n",
    "    test_data = df[test_index:]\n",
    "    print 'Train Data = ', len(train_data), ' Test Data = ', len(test_data)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 258,
=======
   "execution_count": 356,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data =  615  Test Data =  152\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: DEMO For Only 1 (one) 'test' datapoint  vs  all training data points, for visualization purpose"
=======
    "##### Example: DEMO For one test instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting for 3 nearest neighbours\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_Distance(train_feature_vector, test_feature_vector):\n",
    "    ED = np.sqrt(((train_feature_vector - test_feature_vector)**2).sum())\n",
    "    return ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(train_data, test_data, k):\n",
    "        \n",
    "    Y_test_hat = []\n",
    "    \n",
    "    for test_feature_vector in test_data[Features].values:\n",
    "        \n",
    "        E_D_List = []\n",
    "        # Calculating ED between one test data row and all train data rows\n",
    "        for train_feature_vector in train_data[Features].values:\n",
    "            E_D_List.append(Euclidean_Distance(train_feature_vector, test_feature_vector))\n",
    "        \n",
    "        # Storing calulcated list of ED along with the training data for better understanding \n",
    "        train_data_E_D = train_data.copy()\n",
    "        train_data_E_D['Euclidean_Distance'] = E_D_List\n",
    "        \n",
    "        # Sorting the top 'k' rows for k-nearest neighbours based on shortest ED\n",
    "        Top_K_train_data_E_D = train_data_E_D.sort_values(by='Euclidean_Distance').head(k)\n",
    "        \n",
    "        # Finding out the majoirty class value present for k-nearest neighbours\n",
    "        Top_K_train_data_E_D_majorityClass = Top_K_train_data_E_D['Class'].mode()[0]\n",
    "        \n",
    "        # Appending to final predicted values list\n",
    "        Y_test_hat.append(Top_K_train_data_E_D_majorityClass)\n",
    "        \n",
    "    return test_feature_vector, train_data_E_D, Top_K_train_data_E_D, Y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_vector, train_data_E_D, Top_K_train_data_E_D, Y_test_hat = KNN(train_data, test_data.head(1), k)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 259,
=======
   "execution_count": 360,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>-0.547562</td>\n",
       "      <td>0.628834</td>\n",
       "      <td>-0.573754</td>\n",
       "      <td>0.843992</td>\n",
       "      <td>0.418248</td>\n",
       "      <td>-0.83618</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>-0.785774</td>\n",
       "      <td>0</td>\n",
=======
       "      <th>616</th>\n",
       "      <td>-0.547562</td>\n",
       "      <td>-0.966281</td>\n",
       "      <td>-0.057113</td>\n",
       "      <td>1.34549</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.093936</td>\n",
       "      <td>-0.530677</td>\n",
       "      <td>1</td>\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0 -0.547562      0.628834        -0.573754             0.843992   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  Class  \n",
       "0       0.418248      -0.83618       0.685494 -0.785774      0  "
      ]
     },
     "execution_count": 259,
=======
       "        Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "616 -0.547562     -0.966281        -0.057113              1.34549   \n",
       "\n",
       "     Beta_nagative  Beta_postive  Blood_workout       Age  Class  \n",
       "616      -0.692439      0.787328       0.093936 -0.530677      1  "
      ]
     },
     "execution_count": 360,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# This is our 1st train data sample\n",
    "train_data.head(1)"
=======
    "# This is our 1st test data sample\n",
    "\n",
    "test_data.head(1)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 260,
=======
   "execution_count": 361,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>616</th>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.47245</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.100528</td>\n",
       "      <td>2.143261</td>\n",
       "      <td>-0.955839</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>-0.403299</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.189314</td>\n",
       "      <td>1.458141</td>\n",
       "      <td>-0.020483</td>\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "        Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "616  0.045984       0.47245         0.046215            -1.287373   \n",
       "\n",
       "     Beta_nagative  Beta_postive  Blood_workout       Age  Class  \n",
       "616      -0.692439     -0.100528       2.143261 -0.955839      1  "
      ]
     },
     "execution_count": 260,
=======
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0  1.233077     -0.403299         0.046215            -1.287373   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  Class  \n",
       "0      -0.692439     -0.189314       1.458141 -0.020483      1  "
      ]
     },
     "execution_count": 361,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# This is our 1st test data sample\n",
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance between '1 train sample' & '1 test sample' is =  3.19885116094 units\n"
     ]
    }
   ],
   "source": [
    "# dist = ROOT{SUM[(Xik - Xjk)^2]} = ROOT{(Xi1-Xj1)^2 + (Xi2-Xj2)^2 + (Xi3-Xj3)^2 + (Xi4-Xj4)... + (Xin-Xjn)^2}; k - no. features\n",
    "Distance = (train_data.head(1).values[0] - test_data.head(1).values[0])**2\n",
    "Distance = np.sqrt(Distance.sum())\n",
    "print \"Euclidean Distance between '1 train sample' & '1 test sample' is = \", Distance, 'units'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to compute 'distance' between all training and testing data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1: Simple Euclidean Distance (ED)\n",
    "\n",
    "Assuming all features are equally importnant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_Distance(train_feature_vector, test_feature_vector):\n",
    "    ED = np.sqrt(((train_feature_vector - test_feature_vector)**2).sum())\n",
    "    return ED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method2: Weighted Euclidean Distance : Weights for importance (W_ED)\n",
    "Assuming some features are more importnant than others, hence giving bigger value of weights to important features and smaller value of weights to less important feature and zero value of weights to insignificant ones"
=======
    "# This is our 1st train data sample\n",
    "\n",
    "train_data.head(1)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 350,
=======
   "execution_count": 362,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>Class</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Level</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.390597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iron_content</th>\n",
       "      <td>0.466581</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calcium_content</th>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.024118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta_nagative</th>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.163082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta_postive</th>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.566921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood_workout</th>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.270915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.431587</td>\n",
=======
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Euclidean_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>-0.403299</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.189314</td>\n",
       "      <td>1.458141</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>1</td>\n",
       "      <td>3.674976</td>\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                        Class   Weights\n",
       "Level                0.221898  0.390597\n",
       "Iron_content         0.466581  1.000000\n",
       "Calcium_content      0.065068  0.000000\n",
       "Vitamins_deficiency  0.074752  0.024118\n",
       "Beta_nagative        0.130548  0.163082\n",
       "Beta_postive         0.292695  0.566921\n",
       "Blood_workout        0.173844  0.270915\n",
       "Age                  0.238356  0.431587"
      ]
     },
     "execution_count": 350,
=======
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0  1.233077     -0.403299         0.046215            -1.287373   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  Class  \\\n",
       "0      -0.692439     -0.189314       1.458141 -0.020483      1   \n",
       "\n",
       "   Euclidean_Distance  \n",
       "0            3.674976  "
      ]
     },
     "execution_count": 362,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Finding correlation matrix between all features and target 'class'\n",
    "Correlation = df.corr()['Class']\n",
    "Correlation = pd.DataFrame(Correlation)\n",
    "\n",
    "# Removing self correlation of 'class', present at last index\n",
    "Correlation = Correlation[:-1] \n",
    "\n",
    "# Weights found out by Weighting Function (Normalizing correlation values)\n",
    "#               X - X_min\n",
    "#  X_norm  = ---------------\n",
    "#             X_max - X_min\n",
    "# ...-> Maximum value becomes 1 and the min value becomes 0 and others are squished between [0, 1]\n",
    "#\n",
    "Correlation['Weights'] = (Correlation.Class - min(Correlation.Class))/(max(Correlation.Class) - min(Correlation.Class))\n",
    "Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation Matrix _**Assumed**_ weights based on Correlation values and put into a weighting function (i.e. function used here to weight is 'Normalization')"
=======
    "# This is ED put between 1st test_data and 1st train_data sample, put on train_data\n",
    "\n",
    "train_data_E_D.head(1)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calulated Distance weighted Eucledian Distance. Weights are assumed.\n",
    "def Weighted_Euclidean_Distance(train_feature_vector, test_feature_vector):\n",
    "    \n",
    "    W_ED = 0\n",
    "    \n",
    "    # Weight_vector = [W1, W2, W3, ..., W8 ] ; Where, W_i = Weight associated with feature_i\n",
    "    Weight_vector = np.array(Correlation['Weights'])\n",
    "    \n",
    "    # W_ED = sqrt[ W1(x2-x1)^2 + W2(x2-x1)^2 + ... + Wn(x2-x1)^2 ]\n",
    "    W_ED = Weight_vector * (train_feature_vector - test_feature_vector)**2\n",
    "    W_ED = np.sqrt(W_ED.sum())\n",
    "    \n",
    "    return W_ED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:- Finding top 'k' neighbours using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.KNN using:\n",
    "    - Simple Euclidean Distance\n",
    "    - Simple Majority Voting"
=======
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Euclidean_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>-0.403299</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.189314</td>\n",
       "      <td>1.458141</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>1</td>\n",
       "      <td>3.674976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-0.559683</td>\n",
       "      <td>-2.020348</td>\n",
       "      <td>1.094741</td>\n",
       "      <td>0.027772</td>\n",
       "      <td>1.434195</td>\n",
       "      <td>-0.871873</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>0</td>\n",
       "      <td>2.510137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>1.879904</td>\n",
       "      <td>-0.057113</td>\n",
       "      <td>0.969366</td>\n",
       "      <td>3.602795</td>\n",
       "      <td>-0.240048</td>\n",
       "      <td>0.431969</td>\n",
       "      <td>2.275390</td>\n",
       "      <td>1</td>\n",
       "      <td>6.237446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250789</td>\n",
       "      <td>-0.465853</td>\n",
       "      <td>-0.780410</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0.678565</td>\n",
       "      <td>-0.138579</td>\n",
       "      <td>-0.542894</td>\n",
       "      <td>-0.785774</td>\n",
       "      <td>0</td>\n",
       "      <td>2.408783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-0.747344</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>-0.347065</td>\n",
       "      <td>0.522374</td>\n",
       "      <td>-1.115221</td>\n",
       "      <td>0.045646</td>\n",
       "      <td>-0.955839</td>\n",
       "      <td>0</td>\n",
       "      <td>2.879233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0  1.233077     -0.403299         0.046215            -1.287373   \n",
       "1 -0.844335     -0.559683        -2.020348             1.094741   \n",
       "2  1.233077      1.879904        -0.057113             0.969366   \n",
       "3 -0.250789     -0.465853        -0.780410             0.029058   \n",
       "4 -0.844335     -0.747344        -0.160441            -0.347065   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  Class  \\\n",
       "0      -0.692439     -0.189314       1.458141 -0.020483      1   \n",
       "1       0.027772      1.434195      -0.871873 -0.020483      0   \n",
       "2       3.602795     -0.240048       0.431969  2.275390      1   \n",
       "3       0.678565     -0.138579      -0.542894 -0.785774      0   \n",
       "4       0.522374     -1.115221       0.045646 -0.955839      0   \n",
       "\n",
       "   Euclidean_Distance  \n",
       "0            3.674976  \n",
       "1            2.510137  \n",
       "2            6.237446  \n",
       "3            2.408783  \n",
       "4            2.879233  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Euclidean Distance between \n",
    "#                             Data point1 - 1st test data sample (test_feature_vector) \n",
    "#                             Data point2 - all train data.\n",
    "train_data_E_D.head()"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN(train_data, test_data, k):\n",
    "    \n",
    "    Y_test_hat = []\n",
    "    \n",
    "    for test_feature_vector in test_data[Features].values:\n",
    "        \n",
    "        ED_List = []\n",
    "        \n",
    "        # # DISTANCE MEASUREMENT - Using Method 1: Simple Euclidean Distance\n",
    "        #\n",
    "        # Calculating ED between each test data row and all train data rows\n",
    "        for train_feature_vector in train_data[Features].values:\n",
    "            ED_List.append(Euclidean_Distance(train_feature_vector, test_feature_vector))\n",
    "        \n",
    "        # Storing calulcated list of ED along with the training data for better understanding \n",
    "        train_data_ED = train_data.copy()\n",
    "        train_data_ED['Euclidean_Distance'] = ED_List\n",
    "        \n",
    "        # Sorting the top 'k' rows for k-nearest neighbours based on shortest ED\n",
    "        train_data_ED = train_data_ED.sort_values(by='Euclidean_Distance').head(k)\n",
    "        \n",
    "        # # VOTING PROCESS - Using Method 1: Simple Majority Voting\n",
    "        #\n",
    "        # Finding out the majoirty class value present for k-nearest neighbours\n",
    "        majorityClass = train_data_ED['Class'].mode()[0]\n",
    "        \n",
    "        # Appending to final predicted values list\n",
    "        Y_test_hat.append(majorityClass)\n",
    "        \n",
    "    return Y_test_hat"
=======
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Euclidean_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-1.060111</td>\n",
       "      <td>-0.470426</td>\n",
       "      <td>1.032053</td>\n",
       "      <td>-0.041646</td>\n",
       "      <td>0.660492</td>\n",
       "      <td>0.112045</td>\n",
       "      <td>-0.955839</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.250789</td>\n",
       "      <td>-1.153942</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.718617</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>0.660492</td>\n",
       "      <td>-0.618348</td>\n",
       "      <td>-0.445645</td>\n",
       "      <td>0</td>\n",
       "      <td>1.043855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.547562</td>\n",
       "      <td>-0.653513</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>1.972362</td>\n",
       "      <td>-0.197837</td>\n",
       "      <td>1.079052</td>\n",
       "      <td>0.619094</td>\n",
       "      <td>-0.700742</td>\n",
       "      <td>0</td>\n",
       "      <td>1.065794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "381 -0.844335     -1.060111        -0.470426             1.032053   \n",
       "61  -0.250789     -1.153942         0.149543             0.718617   \n",
       "69  -0.547562     -0.653513         0.046215             1.972362   \n",
       "\n",
       "     Beta_nagative  Beta_postive  Blood_workout       Age  Class  \\\n",
       "381      -0.041646      0.660492       0.112045 -0.955839      0   \n",
       "61       -0.692439      0.660492      -0.618348 -0.445645      0   \n",
       "69       -0.197837      1.079052       0.619094 -0.700742      0   \n",
       "\n",
       "     Euclidean_Distance  \n",
       "381            0.993306  \n",
       "61             1.043855  \n",
       "69             1.065794  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected 'k' shortest ED\n",
    "\n",
    "Top_K_train_data_E_D"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_hat_KNN = KNN(train_data, test_data, k)"
=======
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_hat"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "2.Distance Weighted KNN (WKNN) using:\n",
    "    - Weighted Euclidean Distance\n",
    "    - Distance Weighted Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WKNN Formula](Data/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'A Novel Weighted Voting for K-Nearest' by (P)Jianping Gou"
=======
    "#### For all Testing Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting for 3 nearest neighbours\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_Distance(train_feature_vector, test_feature_vector):\n",
    "    ED = np.sqrt(((train_feature_vector - test_feature_vector)**2).sum())\n",
    "    return ED"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 354,
=======
   "execution_count": 367,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def WKNN(train_data, test_data, k):\n",
    "    \n",
    "    Y_test_hat = []\n",
    "    \n",
    "    for test_feature_vector in test_data[Features].values:\n",
    "        WED_List = []\n",
    "        \n",
    "        # # DISTANCE MEASUREMENT - Using Method 2: Weighted Euclidean Distance\n",
    "        #\n",
    "        # Calculating W_ED between each test data row and all train data rows\n",
    "        for train_feature_vector in train_data[Features].values:\n",
    "            WED_List.append(Weighted_Euclidean_Distance(train_feature_vector, test_feature_vector))\n",
    "\n",
    "        # Storing calulcated list of ED along with the training data for better understanding \n",
    "        train_data_WED = train_data.copy()\n",
    "        train_data_WED['Weighted_Euclidean_Distance'] = WED_List\n",
    "\n",
    "        # Sorting the top 'k' rows for k-nearest neighbours based on shortest ED\n",
    "        train_data_WED = train_data_WED.sort_values(by='Weighted_Euclidean_Distance').head(k)\n",
    "\n",
    "        # # VOTING PROCESS - Using Method 2: Distance Weighted Voting\n",
    "        # \n",
    "        #         d_max - d_i \n",
    "        # W_i =  -------------  ;  W_i corresponds to individual weights to each row\n",
    "        #        d_max - d_min\n",
    "        #\n",
    "        # P(1) = Count(1)/Total x SUM(Weights_1s)\n",
    "        # P(0) = COunt(0)/Total X SUM(Weights_0s)\n",
    "\n",
    "        # Storing Counts\n",
    "        Class_0_Size = len(train_data_WED[train_data_WED.Class == 0])\n",
    "        Class_1_Size = len(train_data_WED[train_data_WED.Class == 1])\n",
    "        Total_size = k \n",
    "\n",
    "        # Calculating W_i\n",
    "        d_i = train_data_WED['Weighted_Euclidean_Distance']\n",
    "        train_data_WED['Weights'] = (max(d_i) - d_i)/(max(d_i) - min(d_i))\n",
    "\n",
    "        # Summing Weights for each class; W(0) = W_1 + W_3 + W_4\n",
    "        #                                 W(1) = W_2 + W_5 \n",
    "        Class_0_Weights_SUM = train_data_WED[train_data_WED.Class == 0]['Weights'].sum()\n",
    "        Class_1_Weights_SUM = train_data_WED[train_data_WED.Class == 1]['Weights'].sum()\n",
    "\n",
    "        # Calculating Weight * P(Class)\n",
    "        Weighted_Vote_0 = (1.0*Class_0_Size/Total_size) * Class_0_Weights_SUM\n",
    "        Weighted_Vote_1 = (1.0*Class_1_Size/Total_size) * Class_1_Weights_SUM\n",
    "\n",
    "        if Weighted_Vote_0 > Weighted_Vote_1:\n",
    "            Y_test_hat.append(0)\n",
    "        else:\n",
    "            Y_test_hat.append(1)\n",
=======
    "def KNN(train_data, test_data, k):\n",
    "        \n",
    "    Y_test_hat = []\n",
    "    \n",
    "    for test_feature_vector in test_data[Features].values:\n",
    "        \n",
    "        E_D_List = []\n",
    "        # Calculating ED between each test data row and all train data rows\n",
    "        for train_feature_vector in train_data[Features].values:\n",
    "            E_D_List.append(Euclidean_Distance(train_feature_vector, test_feature_vector))\n",
    "        \n",
    "        # Storing calulcated list of ED along with the training data for better understanding \n",
    "        train_data_E_D = train_data.copy()\n",
    "        train_data_E_D['Euclidean_Distance'] = E_D_List\n",
    "        \n",
    "        # Sorting the top 'k' rows for k-nearest neighbours based on shortest ED\n",
    "        Top_K_train_data_E_D = train_data_E_D.sort_values(by='Euclidean_Distance').head(k)\n",
    "        \n",
    "        # Finding out the majoirty class value present for k-nearest neighbours\n",
    "        Top_K_train_data_E_D_majorityClass = Top_K_train_data_E_D['Class'].mode()[0]\n",
    "        \n",
    "        # Appending to final predicted values list\n",
    "        Y_test_hat.append(Top_K_train_data_E_D_majorityClass)\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
    "        \n",
    "    return Y_test_hat"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 355,
=======
   "execution_count": 377,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "Y_hat_WKNN = WKNN(train_data, test_data, k)"
=======
    "Y_test_hat = KNN(train_data, test_data, k)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (KNN) = 76.32%\n",
      "Accuracy (WKNN) = 77.63%\n"
=======
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    \n",
    "    if list(test_data.Class)[i] == Y_test_hat[i]:\n",
    "        score.append(100)\n",
    "    else:\n",
    "        score.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Actual Y</th>\n",
       "      <th>Predicted Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy Score  Actual Y  Predicted Y\n",
       "616               0         1            0\n",
       "617             100         0            0\n",
       "618               0         0            1\n",
       "619             100         1            1\n",
       "620             100         1            1"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_matrix = pd.DataFrame({'Actual Y': test_data.Class,\n",
    "                                'Predicted Y': Y_test_hat,\n",
    "                                'Accuracy Score': score})\n",
    "\n",
    "accuracy_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 74.3421052632%\n"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "score_KNN,  score_WKNN = 0, 0\n",
    "\n",
    "for y, y_1, y_2 in zip(test_data.Class, Y_hat_KNN, Y_hat_WKNN):\n",
    "    \n",
    "    if y == y_1:\n",
    "        score_KNN +=1\n",
    "    \n",
    "    if y == y_2:\n",
    "        score_WKNN +=1\n",
    "\n",
    "score_KNN, score_WKNN = 100.0*score_KNN/len(test_data), 100.0*score_WKNN/len(test_data)\n",
    "\n",
    "print \"Accuracy (KNN) = {}%\\nAccuracy (WKNN) = {}%\".format(round(score_KNN, 2), round(score_WKNN, 2))"
=======
    "print \"Accuracy Score = {}%\".format(accuracy_matrix['Accuracy Score'].mean())"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sklearn in-built libraries..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 561,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
<<<<<<< HEAD
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
=======
    "from sklearn.metrics import accuracy_score, classification_report\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": 568,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  Iron_content  Calcium_content  Vitamins_deficiency  Beta_nagative  \\\n",
       "0      6           148               72                   35              0   \n",
       "1      1            85               66                   29              0   \n",
       "2      8           183               64                    0              0   \n",
       "3      1            89               66                   23             94   \n",
       "4      0           137               40                   35            168   \n",
       "\n",
       "   Beta_postive  Blood_workout  Age  Class  \n",
       "0          33.6          0.627   50      1  \n",
       "1          26.6          0.351   31      0  \n",
       "2          23.3          0.672   32      1  \n",
       "3          28.1          0.167   21      0  \n",
       "4          43.1          2.288   33      1  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 66,
=======
     "execution_count": 568,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "df = pd.read_csv('Data/data_5_2_pima-indians-diabetes.data.csv')\n",
=======
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
=======
   "execution_count": 569,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 67,
=======
     "execution_count": 569,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Features = list(df.columns)\n",
    "Features.remove(\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[Features]\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation "
=======
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Features = list(df.columns)\n",
    "Features.remove(\"Class\")"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "`Most of the machine learning algorithms are based on the calculation of Euclidean distance between data points, which will be affected if the data is not on same scale and the results will be highly skewed. `\n",
    "\n",
    "`Thus, weightage will be improper and influenced`\n",
    "\n",
    " - Example, 5kg and 5000g\n",
    "\n",
    "    - For a test sample, let's say of 10 kg - \n",
    "\n",
    "    - ED (5, 10) = 5\n",
    "\n",
    "    - ED (5000, 10) = 4990\n",
    "\n",
    "`Both are theoretically equal and same, but for the model, 5 is closer (as ED is less) while 5000 is quite far, thus will exhibit 5's class.`"
=======
    "## X, Y"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 70,
=======
   "execution_count": 571,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "Standardization = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Standardization.fit(X)"
=======
    "X = df[Features]\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Standardization.transform(X)"
=======
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 768 Rows;  Train Data = 614 rows;  Test Data = 154 rows\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80)\n",
    "\n",
    "print \"Total = {} Rows;  Train Data = {} rows;  Test Data = {} rows\".format(len(df), len(X_train), len(X_test))"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
=======
   "execution_count": 545,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Iron_content</th>\n",
       "      <th>Calcium_content</th>\n",
       "      <th>Vitamins_deficiency</th>\n",
       "      <th>Beta_nagative</th>\n",
       "      <th>Beta_postive</th>\n",
       "      <th>Blood_workout</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
=======
       "      <th>251</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.191</td>\n",
       "      <td>25</td>\n",
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "      Level  Iron_content  Calcium_content  Vitamins_deficiency  \\\n",
       "0  0.639947      0.848324         0.149641             0.907270   \n",
       "1 -0.844885     -1.123396        -0.160546             0.530902   \n",
       "2  1.233880      1.943724        -0.263941            -1.288212   \n",
       "3 -0.844885     -0.998208        -0.160546             0.154533   \n",
       "4 -1.141852      0.504055        -1.504687             0.907270   \n",
       "\n",
       "   Beta_nagative  Beta_postive  Blood_workout       Age  \n",
       "0      -0.692891      0.204013       0.468492  1.425995  \n",
       "1      -0.692891     -0.684422      -0.365061 -0.190672  \n",
       "2      -0.692891     -1.103255       0.604397 -0.105584  \n",
       "3       0.123302     -0.494043      -0.920763 -1.041549  \n",
       "4       0.765836      1.409746       5.484909 -0.020496  "
      ]
     },
     "execution_count": 73,
=======
       "     Level  Iron_content  Calcium_content  Vitamins_deficiency  Beta_nagative  \\\n",
       "251      2           129               84                    0              0   \n",
       "694      2            90               60                    0              0   \n",
       "\n",
       "     Beta_postive  Blood_workout  Age  \n",
       "251          28.0          0.284   27  \n",
       "694          23.5          0.191   25  "
      ]
     },
     "execution_count": 545,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "X = pd.DataFrame(X, columns = Features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly - Choosing the a value of 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = sqrt(n)\n",
    "\n",
    "where, n is the total number of data points"
=======
    "X_train.head(2)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 110,
=======
   "execution_count": 640,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "27"
      ]
     },
     "execution_count": 110,
=======
       "251    0\n",
       "694    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 640,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "k = int(np.sqrt(len(X)))\n",
    "k"
=======
    "Y_train[:2]"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = k, weights='uniform')"
=======
    "## Standardisation "
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Prediction"
=======
    "`Most of the machine learning algorithms are based on the calculation of Euclidean distance between data points, which will be affected if the data is not on same scale and the results will be highly skewed. `\n",
    "\n",
    "`Thus, weightage will be improper and influenced`\n",
    "\n",
    " - Example, 5kg and 5000g\n",
    "\n",
    "    - For a test sample, let's say of 10 kg - \n",
    "\n",
    "    - ED (5, 10) = 5\n",
    "\n",
    "    - ED (5000, 10) = 4990\n",
    "\n",
    "`Both are theoretically equal and same, but for the model, 5 is closer (as ED is less) while 5000 is quite far, thus will exhibit 5's class.`"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 332,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_hat = cross_val_predict(KNN, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
=======
   "execution_count": 645,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Standardization = StandardScaler()"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=74.609375\n",
      "[[446  54]\n",
      " [141 127]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.89      0.82       500\n",
      "          1       0.70      0.47      0.57       268\n",
      "\n",
      "avg / total       0.74      0.75      0.73       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy={}\\n{}\\n{}'.format(accuracy_score(Y,Y_hat)*100.0, confusion_matrix(Y,Y_hat), classification_report(Y,Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Precision  : Total positives / Total predicted postives    -> Bot's performance\n",
    "    - Recall     : Total positives / Total actual positives      -> Bot's performance on test data\n",
    "    \n",
    "- Model performing is a little baised towards '0'. Recall for '0' is quite high as compared to that of '1' which means, True Negatives (0) are quite higher than true postives (1).\n",
    "\n",
    "\n",
    "- By confusion matrix it is clear, TN=446 out of total 500 ; TP=127 out of 268"
=======
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Standardization.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = Standardization.transform(X_train)\n",
    "\n",
    "X_test = Standardization.transform(X_test)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Improved Accuracy - Using  *10 Fold CV*"
=======
    "## Choosing the best value of 'k'"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Average Accuracy Scores for 10 Fold CV ... (i.e. 10 times entire Y_hat computed, calculated score and averaged in the end)"
=======
    "k = sqrt(n)\n",
    "\n",
    "where, n is the total number of data points"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Score =  74.609 %\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(KNN, X, Y, cv=10, scoring='accuracy').mean()\n",
    "print 'Average Accuracy Score = ', round(accuracy_score(Y,Y_hat)*100.0,3), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
=======
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(np.sqrt(len(X_train)))\n",
    "k"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Hyperparameter Tuning: GridSearchCV (best vaue of 'k' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_params = {'n_neighbors': range(1,50), 'weights': ['uniform', 'distance'], 'p': [1,2]}"
=======
    "## Model"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 149,
=======
   "execution_count": 627,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "grid = GridSearchCV(KNN, grid_params, cv=10, scoring='accuracy')"
=======
    "KNN = KNeighborsClassifier(n_neighbors = k)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 150,
=======
   "execution_count": 628,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'weights': ['uniform', 'distance'], 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 150,
=======
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 628,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "grid.fit(X, Y)"
=======
    "KNN.fit(X_train, Y_train)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Best model "
=======
    "## Predictions"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=24, p=1,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
=======
   "execution_count": 629,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = KNN.predict(X_test)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Best Parameters"
=======
    "## Accuracy"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 152,
=======
   "execution_count": 634,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'n_neighbors': 24, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "execution_count": 152,
=======
       "79.220779220779221"
      ]
     },
     "execution_count": 634,
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "grid.best_params_"
=======
    "accuracy_score(Y_test, Y_test_hat)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86       102\n",
      "          1       0.81      0.50      0.62        52\n",
      "\n",
      "avg / total       0.80      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(Y_test, Y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Precision  : Total positives / Total predicted postives    -> Bot's performance\n",
    "    - Recall     : Total positives / Total actual positives      -> Bot's performance on test data"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### Best Overall Accuracy Score"
=======
    "## Finding out the best vaue of 'k' "
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7643229166666666"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the best model will have:-\n",
    "    - k=24,\n",
    "    - p=1, \n",
    "    - Distance Weighted Eucledian Distance formula."
=======
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    big = 0\n",
    "    best_k = 0\n",
    "    \n",
    "    for k in range(1, 100):\n",
    "        \n",
    "        KNN = KNeighborsClassifier(n_neighbors = k)\n",
    "        \n",
    "        KNN.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_test_hat = KNN.predict(X_test)\n",
    "        \n",
    "        score = accuracy_score(Y_test, Y_test_hat)*100\n",
    "        \n",
    "        if score > big:\n",
    "            big = score\n",
    "            best_k = k\n",
    "\n",
    "    return big, best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k = 19, with accuracy score = 83.1168831169 %\n"
     ]
    }
   ],
   "source": [
    "big, best_k = KNN(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "print 'Best value of k = {}, with accuracy score = {} %'.format(best_k, big)"
>>>>>>> 064cb46e452f3f2358028224a2a89116300c2e41
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
